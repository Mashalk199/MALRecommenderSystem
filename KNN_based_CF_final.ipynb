{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0FI6PdE1YoN"
   },
   "source": [
    "# Import Necessary Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qwRX_2RCrWdg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJRU5o4d1iCC"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/Mashal/Documents/Projects/MAL Recommender System')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z90r54XGrmPj"
   },
   "source": [
    "# Split Dataset into Training Dataset and Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>my_watched_episodes</th>\n",
       "      <th>my_start_date</th>\n",
       "      <th>my_finish_date</th>\n",
       "      <th>my_score</th>\n",
       "      <th>my_status</th>\n",
       "      <th>my_rewatching</th>\n",
       "      <th>my_rewatching_ep</th>\n",
       "      <th>my_last_updated</th>\n",
       "      <th>my_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>21</td>\n",
       "      <td>586</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-03 10:52:53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-10 13:54:51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>74</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04-27 16:43:35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-03 10:53:57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>178</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-27 15:59:13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284025</th>\n",
       "      <td>Yokonightcore</td>\n",
       "      <td>15611</td>\n",
       "      <td>48</td>\n",
       "      <td>2014-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-07 17:33:03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284026</th>\n",
       "      <td>Yokonightcore</td>\n",
       "      <td>27815</td>\n",
       "      <td>22</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-07 17:32:05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284027</th>\n",
       "      <td>wargod</td>\n",
       "      <td>5945</td>\n",
       "      <td>39</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-03-29 04:24:12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284028</th>\n",
       "      <td>JMc_SetoKai_LoVe</td>\n",
       "      <td>1316</td>\n",
       "      <td>52</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-12-23 05:45:14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284029</th>\n",
       "      <td>hinogurl_mikha</td>\n",
       "      <td>1744</td>\n",
       "      <td>58</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-04-05 11:36:20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31284030 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  username  anime_id  my_watched_episodes my_start_date  \\\n",
       "0                 karthiga        21                  586    0000-00-00   \n",
       "1                 karthiga        59                   26    0000-00-00   \n",
       "2                 karthiga        74                   26    0000-00-00   \n",
       "3                 karthiga       120                   26    0000-00-00   \n",
       "4                 karthiga       178                   26    0000-00-00   \n",
       "...                    ...       ...                  ...           ...   \n",
       "31284025     Yokonightcore     15611                   48    2014-00-00   \n",
       "31284026     Yokonightcore     27815                   22    0000-00-00   \n",
       "31284027            wargod      5945                   39    0000-00-00   \n",
       "31284028  JMc_SetoKai_LoVe      1316                   52    0000-00-00   \n",
       "31284029    hinogurl_mikha      1744                   58    0000-00-00   \n",
       "\n",
       "         my_finish_date  my_score  my_status  my_rewatching  my_rewatching_ep  \\\n",
       "0            0000-00-00         9          1            NaN                 0   \n",
       "1            0000-00-00         7          2            NaN                 0   \n",
       "2            0000-00-00         7          2            NaN                 0   \n",
       "3            0000-00-00         7          2            NaN                 0   \n",
       "4            0000-00-00         7          2            0.0                 0   \n",
       "...                 ...       ...        ...            ...               ...   \n",
       "31284025     0000-00-00         9          1            NaN                 0   \n",
       "31284026     0000-00-00         9          1            NaN                 0   \n",
       "31284027     0000-00-00         8          2            0.0                 0   \n",
       "31284028     0000-00-00         9          2            NaN                 0   \n",
       "31284029     0000-00-00        10          1            0.0                 0   \n",
       "\n",
       "              my_last_updated my_tags  \n",
       "0         2013-03-03 10:52:53     NaN  \n",
       "1         2013-03-10 13:54:51     NaN  \n",
       "2         2013-04-27 16:43:35     NaN  \n",
       "3         2013-03-03 10:53:57     NaN  \n",
       "4         2013-03-27 15:59:13     NaN  \n",
       "...                       ...     ...  \n",
       "31284025  2015-09-07 17:33:03     NaN  \n",
       "31284026  2015-09-07 17:32:05     NaN  \n",
       "31284027  2010-03-29 04:24:12     NaN  \n",
       "31284028  2009-12-23 05:45:14     NaN  \n",
       "31284029  2008-04-05 11:36:20     NaN  \n",
       "\n",
       "[31284030 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv('../animelists_cleaned.csv')\n",
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows where username is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.dropna(subset=['username'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a sample of 10% of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                username  anime_id  my_watched_episodes my_start_date  \\\n",
      "12140562     blender1423     11887                   13    0000-00-00   \n",
      "10344646       Saranyaan     22297                    0    0000-00-00   \n",
      "11017077   werewolfofusa     12069                    1    0000-00-00   \n",
      "9601319        wizardsky     24277                   24    0000-00-00   \n",
      "4907282            Sadid     28977                    0    0000-00-00   \n",
      "...                  ...       ...                  ...           ...   \n",
      "4247933   AugustusGaspar     34984                    0    0000-00-00   \n",
      "25906237    eau-de-gloom     19383                   13    0000-00-00   \n",
      "26583048        pabblete      8795                   13    0000-00-00   \n",
      "3962380         idlezeal      6007                    1    0000-00-00   \n",
      "11252868         Daisuki     35376                    0    0000-00-00   \n",
      "\n",
      "         my_finish_date  my_score  my_status  my_rewatching  my_rewatching_ep  \\\n",
      "12140562     0000-00-00         7          2            0.0                 0   \n",
      "10344646     0000-00-00         0          6            0.0                 0   \n",
      "11017077     0000-00-00        10          2            0.0                 0   \n",
      "9601319      0000-00-00         8          2            0.0                 0   \n",
      "4907282      0000-00-00         0          6            0.0                 0   \n",
      "...                 ...       ...        ...            ...               ...   \n",
      "4247933      0000-00-00         0          6            0.0                 0   \n",
      "25906237     0000-00-00         8          2            0.0                 0   \n",
      "26583048     0000-00-00         8          2            NaN                 0   \n",
      "3962380      0000-00-00         6          2            0.0                 0   \n",
      "11252868     0000-00-00         0          6            0.0                 0   \n",
      "\n",
      "              my_last_updated    my_tags  \n",
      "12140562  2017-09-04 13:42:06        NaN  \n",
      "10344646  2014-09-06 00:04:07        NaN  \n",
      "11017077  2012-03-21 20:22:44        NaN  \n",
      "9601319   2017-01-27 18:37:34        NaN  \n",
      "4907282   2018-04-04 15:11:06        NaN  \n",
      "...                       ...        ...  \n",
      "4247933   2017-08-05 06:03:14        NaN  \n",
      "25906237  2018-03-26 11:49:58        NaN  \n",
      "26583048  2011-04-08 23:27:18        NaN  \n",
      "3962380   2010-05-01 08:09:21        NaN  \n",
      "11252868  2017-04-25 11:44:06  Fall 2017  \n",
      "\n",
      "[31284 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# random_state for reproducibility\n",
    "anime_df = full_df.sample(frac=0.001, random_state=seed)  \n",
    "print(anime_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = anime_df['anime_id'].unique()\n",
    "# Gets list of unique IDs and sorts them\n",
    "unique_ids = np.sort(unique_ids)\n",
    "# Contains translations from anime IDs to numpy array indices\n",
    "idToInd = {}\n",
    "# Initialises array to size of unique IDs, but will change contents to ascending order\n",
    "indToId = np.array(unique_ids)\n",
    "for i in range(len(unique_ids)):\n",
    "    idToInd[unique_ids[i]] = i\n",
    "    indToId[i] = unique_ids[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds user ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_df['user_id'] = pd.factorize(anime_df['username'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KlU-Lq16rlpN",
    "outputId": "652c555a-4e2e-478c-ebd5-bfb0dcb65eac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(               username  anime_id  my_watched_episodes my_start_date  \\\n",
       " 27830841    Shortredguy      5682                    0    0000-00-00   \n",
       " 6174958        Flairway     15109                   12    0000-00-00   \n",
       " 18489765         ance25      2743                    0    0000-00-00   \n",
       " 15058251   Sorrowsenpai      5702                    4    0000-00-00   \n",
       " 1384018   TheVirginMary      9989                   11    0000-00-00   \n",
       " ...                 ...       ...                  ...           ...   \n",
       " 2612752     TCarneiro71     35203                   12    2017-07-11   \n",
       " 16222571  crimsonking12       658                   26    0000-00-00   \n",
       " 28689727    AisakiPanda      4722                   25    0000-00-00   \n",
       " 19170851    Akari-Light        20                  135    0000-00-00   \n",
       " 27230616   SophiaHyuuga     23847                   13    2015-04-07   \n",
       " \n",
       "          my_finish_date  my_score  my_status  my_rewatching  my_rewatching_ep  \\\n",
       " 27830841     0000-00-00         0          6            0.0                 0   \n",
       " 6174958      0000-00-00         7          2            0.0                 0   \n",
       " 18489765     0000-00-00         0          6            0.0                 0   \n",
       " 15058251     0000-00-00         5          2            0.0                 0   \n",
       " 1384018      2011-06-25        10          2            0.0                 0   \n",
       " ...                 ...       ...        ...            ...               ...   \n",
       " 2612752      2017-09-26         7          2            0.0                 0   \n",
       " 16222571     0000-00-00         7          2            NaN                 0   \n",
       " 28689727     0000-00-00        10          2            0.0                 0   \n",
       " 19170851     0000-00-00        10          1            0.0                 0   \n",
       " 27230616     2015-09-13         7          2            0.0                 0   \n",
       " \n",
       "               my_last_updated my_tags  user_id  \n",
       " 27830841  2010-12-21 01:19:25     NaN     6361  \n",
       " 6174958   2013-04-24 01:17:37     NaN     5646  \n",
       " 18489765  2008-09-29 08:21:57     NaN     1954  \n",
       " 15058251  2017-07-27 00:31:53     NaN     9098  \n",
       " 1384018   2011-06-25 12:09:43     NaN      140  \n",
       " ...                       ...     ...      ...  \n",
       " 2612752   2017-09-26 19:39:21     NaN     5517  \n",
       " 16222571  2012-07-12 04:19:45     NaN    14512  \n",
       " 28689727  2013-12-28 21:02:20     NaN    11649  \n",
       " 19170851  2011-03-17 00:58:40     NaN    11236  \n",
       " 27230616  2015-09-13 15:10:47     NaN     6043  \n",
       " \n",
       " [25027 rows x 12 columns],\n",
       "                   username  anime_id  my_watched_episodes my_start_date  \\\n",
       " 6338865             Lolaso     27989                    0    0000-00-00   \n",
       " 19222960       hidekeitaro     22547                    2    0000-00-00   \n",
       " 24249679             Naoti      6956                    0    0000-00-00   \n",
       " 20212740            Tangro      1135                    1    0000-00-00   \n",
       " 12876344           4X_XR3Y     15201                    1    0000-00-00   \n",
       " ...                    ...       ...                  ...           ...   \n",
       " 22139352         Clisthert      1734                    4    0000-00-00   \n",
       " 23729223  Undercover_Otaku      2112                    1    0000-00-00   \n",
       " 360848             bibassi         6                    0    0000-00-00   \n",
       " 3804210           makube-x       244                    0    0000-00-00   \n",
       " 6634684               Xari      5114                    0    0000-00-00   \n",
       " \n",
       "          my_finish_date  my_score  my_status  my_rewatching  my_rewatching_ep  \\\n",
       " 6338865      0000-00-00         0          4            0.0                 0   \n",
       " 19222960     0000-00-00         8          4            NaN                 0   \n",
       " 24249679     0000-00-00         0          6            0.0                 0   \n",
       " 20212740     0000-00-00         8          2            0.0                 0   \n",
       " 12876344     0000-00-00         5          2            0.0                 0   \n",
       " ...                 ...       ...        ...            ...               ...   \n",
       " 22139352     0000-00-00         5          2            0.0                 0   \n",
       " 23729223     0000-00-00         0          4            0.0                 0   \n",
       " 360848       0000-00-00         0          6            0.0                 0   \n",
       " 3804210      0000-00-00         0          6            0.0                 0   \n",
       " 6634684      0000-00-00         0          6            0.0                 0   \n",
       " \n",
       "               my_last_updated my_tags  user_id  \n",
       " 6338865   2017-07-09 16:56:15     NaN    20570  \n",
       " 19222960  2014-04-10 22:34:23     NaN    20415  \n",
       " 24249679  2012-01-02 11:44:15     NaN     8335  \n",
       " 20212740  2016-10-26 20:22:52     NaN     7761  \n",
       " 12876344  2017-07-18 21:29:19     NaN    15877  \n",
       " ...                       ...     ...      ...  \n",
       " 22139352  2012-01-18 22:44:31     NaN     3959  \n",
       " 23729223  2011-07-11 06:16:22     NaN     3221  \n",
       " 360848    2014-11-23 03:53:03     NaN     4201  \n",
       " 3804210   2008-09-15 15:39:27     NaN    18166  \n",
       " 6634684   2014-06-25 03:45:28     NaN     6009  \n",
       " \n",
       " [6257 rows x 12 columns])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(anime_df, test_size=0.2)\n",
    "train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas(Index=27830841, username='Shortredguy', anime_id=5682, my_watched_episodes=0, my_start_date='0000-00-00', my_finish_date='0000-00-00', my_score=0, my_status=6, my_rewatching=0.0, my_rewatching_ep=0, my_last_updated='2010-12-21 01:19:25', my_tags=nan, user_id=6361)\n"
     ]
    }
   ],
   "source": [
    "for row in train_df.itertuples():\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('username', 'anime_id', 'my_watched_episodes', 'my_start_date', 'my_finish_date', 'my_score', 'my_status', 'my_rewatching', 'my_rewatching_ep', 'my_last_updated', 'my_tags', 'user_id')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.itertuples(index=False).__next__()._fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>my_watched_episodes</th>\n",
       "      <th>my_start_date</th>\n",
       "      <th>my_finish_date</th>\n",
       "      <th>my_score</th>\n",
       "      <th>my_status</th>\n",
       "      <th>my_rewatching</th>\n",
       "      <th>my_rewatching_ep</th>\n",
       "      <th>my_last_updated</th>\n",
       "      <th>my_tags</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [username, anime_id, my_watched_episodes, my_start_date, my_finish_date, my_score, my_status, my_rewatching, my_rewatching_ep, my_last_updated, my_tags, user_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_df[(anime_df['user_id']==40352)] #  & (anime_df['anime_id']==indToId[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = anime_df['user_id'].nunique()\n",
    "n_items = anime_df['anime_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>my_watched_episodes</th>\n",
       "      <th>my_start_date</th>\n",
       "      <th>my_finish_date</th>\n",
       "      <th>my_score</th>\n",
       "      <th>my_status</th>\n",
       "      <th>my_rewatching</th>\n",
       "      <th>my_rewatching_ep</th>\n",
       "      <th>my_last_updated</th>\n",
       "      <th>my_tags</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12140562</th>\n",
       "      <td>blender1423</td>\n",
       "      <td>11887</td>\n",
       "      <td>13</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-04 13:42:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10344541</th>\n",
       "      <td>Saranyaan</td>\n",
       "      <td>28223</td>\n",
       "      <td>12</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-31 09:16:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11017077</th>\n",
       "      <td>werewolfofusa</td>\n",
       "      <td>12069</td>\n",
       "      <td>1</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-03-21 20:22:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9601319</th>\n",
       "      <td>wizardsky</td>\n",
       "      <td>24277</td>\n",
       "      <td>24</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-27 18:37:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151701</th>\n",
       "      <td>zillys</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-13 18:57:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26519102</th>\n",
       "      <td>SpiritQ</td>\n",
       "      <td>6574</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-04-01 20:39:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247933</th>\n",
       "      <td>AugustusGaspar</td>\n",
       "      <td>34984</td>\n",
       "      <td>0</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-05 06:03:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25906237</th>\n",
       "      <td>eau-de-gloom</td>\n",
       "      <td>19383</td>\n",
       "      <td>13</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-26 11:49:58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26583048</th>\n",
       "      <td>pabblete</td>\n",
       "      <td>8795</td>\n",
       "      <td>13</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-04-08 23:27:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962380</th>\n",
       "      <td>idlezeal</td>\n",
       "      <td>6007</td>\n",
       "      <td>1</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-05-01 08:09:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25027 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                username  anime_id  my_watched_episodes my_start_date  \\\n",
       "12140562     blender1423     11887                   13    0000-00-00   \n",
       "10344541       Saranyaan     28223                   12    0000-00-00   \n",
       "11017077   werewolfofusa     12069                    1    0000-00-00   \n",
       "9601319        wizardsky     24277                   24    0000-00-00   \n",
       "3151701           zillys        33                   25    0000-00-00   \n",
       "...                  ...       ...                  ...           ...   \n",
       "26519102         SpiritQ      6574                   12    2010-01-12   \n",
       "4247933   AugustusGaspar     34984                    0    0000-00-00   \n",
       "25906237    eau-de-gloom     19383                   13    0000-00-00   \n",
       "26583048        pabblete      8795                   13    0000-00-00   \n",
       "3962380         idlezeal      6007                    1    0000-00-00   \n",
       "\n",
       "         my_finish_date  my_score  my_status  my_rewatching  my_rewatching_ep  \\\n",
       "12140562     0000-00-00         7          2            0.0                 0   \n",
       "10344541     2016-10-31         0          2            NaN                 0   \n",
       "11017077     0000-00-00        10          2            0.0                 0   \n",
       "9601319      0000-00-00         8          2            0.0                 0   \n",
       "3151701      0000-00-00        10          2            NaN                 0   \n",
       "...                 ...       ...        ...            ...               ...   \n",
       "26519102     2010-04-01         9          2            NaN                 0   \n",
       "4247933      0000-00-00         0          6            0.0                 0   \n",
       "25906237     0000-00-00         8          2            0.0                 0   \n",
       "26583048     0000-00-00         8          2            NaN                 0   \n",
       "3962380      0000-00-00         6          2            0.0                 0   \n",
       "\n",
       "              my_last_updated my_tags  user_id  \n",
       "12140562  2017-09-04 13:42:06     NaN        0  \n",
       "10344541  2016-10-31 09:16:19     NaN        1  \n",
       "11017077  2012-03-21 20:22:44     NaN        2  \n",
       "9601319   2017-01-27 18:37:34     NaN        3  \n",
       "3151701   2015-09-13 18:57:23     NaN        5  \n",
       "...                       ...     ...      ...  \n",
       "26519102  2010-04-01 20:39:12     NaN    24004  \n",
       "4247933   2017-08-05 06:03:14     NaN    24005  \n",
       "25906237  2018-03-26 11:49:58     NaN    24006  \n",
       "26583048  2011-04-08 23:27:18     NaN    24007  \n",
       "3962380   2010-05-01 08:09:21     NaN    24008  \n",
       "\n",
       "[25027 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_values(by='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       0     1     2     3     4     5     6     7     8     9     ...  4307  \\\n",
       " 0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " ...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       " 24004   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 24005   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 24006   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 24007   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 24008   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " \n",
       "        4308  4309  4310  4311  4312  4313  4314  4315  4316  \n",
       " 0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " ...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       " 24004   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 24005   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 24006   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 24007   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 24008   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " \n",
       " [24009 rows x 4317 columns],\n",
       "        0     1     2     3     4     5     6     7     8     9     ...  4307  \\\n",
       " 0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " ...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       " 24004   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 24005   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 24006   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 24007   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 24008   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " \n",
       "        4308  4309  4310  4311  4312  4313  4314  4315  4316  \n",
       " 0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " ...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       " 24004   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 24005   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 24006   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 24007   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 24008   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " \n",
       " [24009 rows x 4317 columns])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training dataset\n",
    "train_ds = np.zeros((n_users, n_items))\n",
    "for row in train_df.itertuples():\n",
    "    train_ds[row.user_id, idToInd[row.anime_id]] = row.my_score\n",
    "train_ds = pd.DataFrame(train_ds)\n",
    "\n",
    "# Testing dataset\n",
    "test_ds = np.zeros((n_users, n_items))\n",
    "for row in test_df.itertuples():\n",
    "    test_ds[row.user_id, idToInd[row.anime_id]] = row.my_score\n",
    "test_ds = pd.DataFrame(test_ds)\n",
    "\n",
    "train_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1ffZ6fCjYQ7"
   },
   "source": [
    "# Fitting the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYJZT1keazuc"
   },
   "source": [
    "## User-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bf9Ksc2OlL1"
   },
   "source": [
    "### Compute Pearson Correlation Coefficient for Each Pair of Users in Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SH3O2sX3iBx1",
    "outputId": "7f163ae0-1a1c-4012-e856-c51666c5a7fe"
   },
   "outputs": [],
   "source": [
    "GAMMA = 30\n",
    "EPSILON = 1e-9\n",
    "\n",
    "np_user_pearson_corr = np.zeros((n_users, n_users))\n",
    "\n",
    "for i, user_i_vec in enumerate(train_ds.values):\n",
    "    for j, user_j_vec in enumerate(train_ds.values):\n",
    "\n",
    "        # ratings corated by the current pair od users\n",
    "        mask_i = user_i_vec > 0\n",
    "        mask_j = user_j_vec > 0\n",
    "\n",
    "        # corrated item index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of user_i_vec and user_j_vec\n",
    "        mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "        user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "        r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "        r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "        sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "\n",
    "        np_user_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "np_user_pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OxHrFpIEHYm"
   },
   "source": [
    "### Predict Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-REE2zqj5rt"
   },
   "outputs": [],
   "source": [
    "np_predictions = np.zeros((n_users, n_items))\n",
    "\n",
    "K = 100\n",
    "EPSILON = 1e-9\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "    if rating > 0:\n",
    "        # find top-k most similar users as the current user, remove itself\n",
    "        sim_user_ids = np.argsort(np_user_pearson_corr[i])[-(K + 1):-1]\n",
    "\n",
    "        # the coefficient values of similar users\n",
    "        sim_val = np_user_pearson_corr[i][sim_user_ids]\n",
    "\n",
    "        # the average value of the current user's ratings\n",
    "        sim_users = train_ds.values[sim_user_ids]\n",
    "        user_mean = np.sum(train_ds.values[i]) / (np.sum(np.clip(train_ds.values[i], 0, 1)) + EPSILON)\n",
    "        sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # select the users who rated item j\n",
    "        mask_rated_j = sim_users[:, j] > 0\n",
    "        \n",
    "        # sim(u, v) * (r_vj - mean_v)\n",
    "        sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "\n",
    "        # filter unrated items\n",
    "        #w = np.clip(sim_users[mask_rated_j, j], 0, 1)\n",
    "        #sim_r_sum_mean *= w\n",
    "        #print(sim_users[:, j])\n",
    "        \n",
    "        np_predictions[i][j] = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "        np_predictions[i][j] = np.clip(np_predictions[i][j], 0, 5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiPKuFjQudyM"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQZSW98ZGDJR"
   },
   "source": [
    "#### Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20UzmEf9uhF_",
    "outputId": "94c5c749-6a8c-449c-ba64-eff5427ffcd4"
   },
   "outputs": [],
   "source": [
    "#==================MAE on Testing set===================#\n",
    "labels = test_ds.values\n",
    "\n",
    "# absolute error on all ratings\n",
    "absolute_error = np.abs(np_predictions - labels)\n",
    "\n",
    "# weight\n",
    "weight = np.clip(labels, 0, 1)\n",
    "\n",
    "# absoulte error on rated ratings\n",
    "abs_error = absolute_error * weight\n",
    "\n",
    "# MAE\n",
    "MAE = np.sum(abs_error) / np.sum(weight)\n",
    "\n",
    "print(\"MAE on Tesing set (User-based): \" + str(MAE));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_L7yqJ4HXJa"
   },
   "source": [
    "#### Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mV-BhWhQvtAV",
    "outputId": "dd88af28-6ae9-49e6-fe5c-9077cc345470"
   },
   "outputs": [],
   "source": [
    "#==================RMSE on Testing set===================\n",
    "labels = test_ds.values\n",
    "\n",
    "# squared error on all ratings\n",
    "squared_error = np.square(np_predictions - labels)\n",
    "weight = np.clip(labels, 0, 1)\n",
    "\n",
    "# squared error on rated ratings\n",
    "squared_error = squared_error * weight\n",
    "\n",
    "# RMSE\n",
    "RMSE = np.sqrt(np.sum(squared_error) / np.sum(weight))\n",
    "\n",
    "print(\"RMSE on Tesing set (User-based): \" + str(RMSE));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecoieIQTbQZV"
   },
   "source": [
    "## Item-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XHtJ0LpbQZW"
   },
   "source": [
    "### Compute Pearson Correlation Coefficient for Each Pair of Users in Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgPMV2sobQZW",
    "outputId": "97f5fec9-ce61-4df0-c7c4-050485aa78d3"
   },
   "outputs": [],
   "source": [
    "DELTA = 25\n",
    "EPSILON = 1e-9\n",
    "\n",
    "np_item_pearson_corr = np.zeros((n_items, n_items))\n",
    "\n",
    "for i, item_i_vec in enumerate(train_ds.T.values):\n",
    "    for j, item_j_vec in enumerate(train_ds.T.values):\n",
    "\n",
    "        # ratings corated by the current pair od items\n",
    "        mask_i = item_i_vec > 0\n",
    "        mask_j = item_j_vec > 0\n",
    "\n",
    "        # corrated index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of item_i_vec and item_j_vec\n",
    "        mean_item_i = np.sum(item_i_vec) / (np.sum(np.clip(item_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_item_j = np.sum(item_j_vec) / (np.sum(np.clip(item_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        item_i_sub_mean = item_i_vec[corrated_index] - mean_item_i\n",
    "        item_j_sub_mean = item_j_vec[corrated_index] - mean_item_j\n",
    "\n",
    "        r_ui_sub_ri_sq = np.square(item_i_sub_mean)\n",
    "        r_uj_sub_rj_sq = np.square(item_j_sub_mean)\n",
    "\n",
    "        r_ui_sub_ri_sq_sum_sqrt = np.sqrt(np.sum(r_ui_sub_ri_sq))\n",
    "        r_uj_sub_rj_sq_sum_sqrt = np.sqrt(np.sum(r_uj_sub_rj_sq))\n",
    "\n",
    "        sim = np.sum(item_i_sub_mean * item_j_sub_mean) / (r_ui_sub_ri_sq_sum_sqrt * r_uj_sub_rj_sq_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), DELTA) / DELTA) * sim\n",
    "\n",
    "        np_item_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "np_item_pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EANmxRhbQZX"
   },
   "source": [
    "### Predict Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyysZ6e7bQZX"
   },
   "outputs": [],
   "source": [
    "np_predictions = np.zeros((n_users, n_items))\n",
    "\n",
    "K = 10\n",
    "EPSILON = 1e-9\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "    if rating > 0:\n",
    "        # find top-k most similar items as the current item, remove itself\n",
    "        sim_item_ids = np.argsort(np_item_pearson_corr[j])[-(K + 1):-1]\n",
    "\n",
    "        # the coefficient values of similar items\n",
    "        sim_val = np_item_pearson_corr[j][sim_item_ids]\n",
    "\n",
    "        # the average value of the current item's ratings\n",
    "        sim_items = train_ds.T.values[sim_item_ids]\n",
    "        item_mean = np.sum(train_ds.T.values[j]) / (np.sum(np.clip(train_ds.T.values[j], 0, 1)) + EPSILON)\n",
    "        sim_item_mean = np.sum(sim_items, axis=1) / (np.sum(np.clip(sim_items, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # sim(u, v) * (r_v - mean_v)\n",
    "        sim_r_sum_mean = sim_val * (sim_items[:, i] - sim_item_mean) \n",
    "\n",
    "        # filter unrated items\n",
    "        w = np.clip(sim_items[:, i], 0, 1)\n",
    "        sim_r_sum_mean *= w\n",
    "\n",
    "        np_predictions[i][j] = item_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val * w) + EPSILON)    \n",
    "        np_predictions[i][j] = np.clip(np_predictions[i][j], 0, 5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rIh6rpJbQZY"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbMQzZlibQZY"
   },
   "source": [
    "#### Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bg2OzOBXbQZZ",
    "outputId": "8e032639-a4ca-4d72-8194-7c2a36611e94"
   },
   "outputs": [],
   "source": [
    "#==================MAE on Testing set===================#\n",
    "labels = test_ds.values\n",
    "\n",
    "# absolute error on all ratings\n",
    "absolute_error = np.abs(np_predictions - labels)\n",
    "\n",
    "# weight\n",
    "weight = np.clip(labels, 0, 1)\n",
    "\n",
    "# absoulte error on rated ratings\n",
    "abs_error = absolute_error * weight\n",
    "\n",
    "# MAE\n",
    "MAE = np.sum(abs_error) / np.sum(weight)\n",
    "\n",
    "print(\"MAE on Tesing set (Item-based): \" + str(MAE));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ze_3YW5GbQZZ"
   },
   "source": [
    "#### Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEh_WNPXbQZa",
    "outputId": "3be0306d-72e2-4a82-fc84-06f00b746193"
   },
   "outputs": [],
   "source": [
    "#==================RMSE on Testing set===================#\n",
    "labels = test_ds.values\n",
    "\n",
    "# squared error on all ratings\n",
    "squared_error = np.square(np_predictions - labels)\n",
    "weight = np.clip(labels, 0, 1)\n",
    "\n",
    "# squared error on rated ratings\n",
    "squared_error = squared_error * weight\n",
    "\n",
    "# RMSE\n",
    "RMSE = np.sqrt(np.sum(squared_error) / np.sum(weight))\n",
    "\n",
    "print(\"RMSE on Tesing set (Item-based): \" + str(RMSE));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6be1nHnBRSl9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KNN_based_CF_final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
